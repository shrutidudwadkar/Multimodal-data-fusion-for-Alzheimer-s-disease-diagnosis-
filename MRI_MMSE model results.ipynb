{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "# fixing random seed for reproducibility\n",
    "random.seed(200216758)\n",
    "np.random.seed(200216758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MRI+MMSE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST101SV</th>\n",
       "      <th>ST102CV</th>\n",
       "      <th>ST102SA</th>\n",
       "      <th>ST102TA</th>\n",
       "      <th>ST102TS</th>\n",
       "      <th>ST103CV</th>\n",
       "      <th>ST103SA</th>\n",
       "      <th>ST103TA</th>\n",
       "      <th>ST103TS</th>\n",
       "      <th>ST104CV</th>\n",
       "      <th>...</th>\n",
       "      <th>ST99SA</th>\n",
       "      <th>ST99TA</th>\n",
       "      <th>ST99TS</th>\n",
       "      <th>ST9SV</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1578</td>\n",
       "      <td>2862</td>\n",
       "      <td>1312</td>\n",
       "      <td>2.065</td>\n",
       "      <td>0.609</td>\n",
       "      <td>2305</td>\n",
       "      <td>763</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.795</td>\n",
       "      <td>2934</td>\n",
       "      <td>...</td>\n",
       "      <td>3387</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1623</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>3339</td>\n",
       "      <td>1386</td>\n",
       "      <td>2.297</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1621</td>\n",
       "      <td>631</td>\n",
       "      <td>2.166</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>3046</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1296</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>2719</td>\n",
       "      <td>1477</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1813</td>\n",
       "      <td>622</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.778</td>\n",
       "      <td>3397</td>\n",
       "      <td>...</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>744</td>\n",
       "      <td>3456</td>\n",
       "      <td>1748</td>\n",
       "      <td>1.960</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1792</td>\n",
       "      <td>623</td>\n",
       "      <td>2.496</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3106</td>\n",
       "      <td>...</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1493</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908</td>\n",
       "      <td>2741</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.228</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2095</td>\n",
       "      <td>753</td>\n",
       "      <td>2.518</td>\n",
       "      <td>0.884</td>\n",
       "      <td>3696</td>\n",
       "      <td>...</td>\n",
       "      <td>3375</td>\n",
       "      <td>2.736</td>\n",
       "      <td>0.697</td>\n",
       "      <td>1997</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1487</td>\n",
       "      <td>2814</td>\n",
       "      <td>1437</td>\n",
       "      <td>1.925</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1903</td>\n",
       "      <td>622</td>\n",
       "      <td>2.397</td>\n",
       "      <td>1.023</td>\n",
       "      <td>3919</td>\n",
       "      <td>...</td>\n",
       "      <td>3152</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0.717</td>\n",
       "      <td>2053</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1310</td>\n",
       "      <td>3591</td>\n",
       "      <td>1484</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.699</td>\n",
       "      <td>2257</td>\n",
       "      <td>769</td>\n",
       "      <td>2.470</td>\n",
       "      <td>0.683</td>\n",
       "      <td>3268</td>\n",
       "      <td>...</td>\n",
       "      <td>2966</td>\n",
       "      <td>2.950</td>\n",
       "      <td>0.653</td>\n",
       "      <td>1474</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1628</td>\n",
       "      <td>3152</td>\n",
       "      <td>1437</td>\n",
       "      <td>2.046</td>\n",
       "      <td>0.693</td>\n",
       "      <td>1904</td>\n",
       "      <td>701</td>\n",
       "      <td>2.348</td>\n",
       "      <td>0.709</td>\n",
       "      <td>2647</td>\n",
       "      <td>...</td>\n",
       "      <td>3424</td>\n",
       "      <td>2.737</td>\n",
       "      <td>0.779</td>\n",
       "      <td>3932</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1473</td>\n",
       "      <td>3424</td>\n",
       "      <td>1538</td>\n",
       "      <td>2.135</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1545</td>\n",
       "      <td>609</td>\n",
       "      <td>2.242</td>\n",
       "      <td>0.649</td>\n",
       "      <td>2570</td>\n",
       "      <td>...</td>\n",
       "      <td>2794</td>\n",
       "      <td>3.063</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2651</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1441</td>\n",
       "      <td>4008</td>\n",
       "      <td>1941</td>\n",
       "      <td>2.057</td>\n",
       "      <td>0.558</td>\n",
       "      <td>1895</td>\n",
       "      <td>779</td>\n",
       "      <td>2.102</td>\n",
       "      <td>0.687</td>\n",
       "      <td>4228</td>\n",
       "      <td>...</td>\n",
       "      <td>3488</td>\n",
       "      <td>2.764</td>\n",
       "      <td>0.626</td>\n",
       "      <td>2135</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1324</td>\n",
       "      <td>3340</td>\n",
       "      <td>1783</td>\n",
       "      <td>1.879</td>\n",
       "      <td>0.621</td>\n",
       "      <td>1502</td>\n",
       "      <td>584</td>\n",
       "      <td>2.172</td>\n",
       "      <td>0.916</td>\n",
       "      <td>3147</td>\n",
       "      <td>...</td>\n",
       "      <td>2651</td>\n",
       "      <td>2.225</td>\n",
       "      <td>0.675</td>\n",
       "      <td>2664</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Dementia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1745</td>\n",
       "      <td>3341</td>\n",
       "      <td>1532</td>\n",
       "      <td>2.169</td>\n",
       "      <td>0.629</td>\n",
       "      <td>1749</td>\n",
       "      <td>636</td>\n",
       "      <td>2.234</td>\n",
       "      <td>0.996</td>\n",
       "      <td>4009</td>\n",
       "      <td>...</td>\n",
       "      <td>3420</td>\n",
       "      <td>2.727</td>\n",
       "      <td>0.718</td>\n",
       "      <td>3024</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>Dementia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1380</td>\n",
       "      <td>3118</td>\n",
       "      <td>1402</td>\n",
       "      <td>2.076</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1985</td>\n",
       "      <td>732</td>\n",
       "      <td>2.297</td>\n",
       "      <td>1.025</td>\n",
       "      <td>3281</td>\n",
       "      <td>...</td>\n",
       "      <td>3273</td>\n",
       "      <td>2.835</td>\n",
       "      <td>0.694</td>\n",
       "      <td>2951</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1388</td>\n",
       "      <td>3427</td>\n",
       "      <td>1738</td>\n",
       "      <td>1.872</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1884</td>\n",
       "      <td>603</td>\n",
       "      <td>2.667</td>\n",
       "      <td>0.773</td>\n",
       "      <td>2667</td>\n",
       "      <td>...</td>\n",
       "      <td>2991</td>\n",
       "      <td>2.449</td>\n",
       "      <td>0.704</td>\n",
       "      <td>1693</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1552</td>\n",
       "      <td>3449</td>\n",
       "      <td>1683</td>\n",
       "      <td>2.061</td>\n",
       "      <td>0.531</td>\n",
       "      <td>1761</td>\n",
       "      <td>670</td>\n",
       "      <td>2.248</td>\n",
       "      <td>0.882</td>\n",
       "      <td>2659</td>\n",
       "      <td>...</td>\n",
       "      <td>3280</td>\n",
       "      <td>2.590</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1788</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ST101SV  ST102CV  ST102SA  ST102TA  ST102TS  ST103CV  ST103SA  ST103TA  \\\n",
       "0      1578     2862     1312    2.065    0.609     2305      763    2.650   \n",
       "1      1102     3339     1386    2.297    0.702     1621      631    2.166   \n",
       "2      1226     2719     1477    1.781    0.538     1813      622    2.409   \n",
       "3       744     3456     1748    1.960    0.620     1792      623    2.496   \n",
       "4       908     2741     1216    2.228    0.612     2095      753    2.518   \n",
       "5      1487     2814     1437    1.925    0.592     1903      622    2.397   \n",
       "6      1310     3591     1484    2.238    0.699     2257      769    2.470   \n",
       "7      1628     3152     1437    2.046    0.693     1904      701    2.348   \n",
       "8      1473     3424     1538    2.135    0.580     1545      609    2.242   \n",
       "9      1441     4008     1941    2.057    0.558     1895      779    2.102   \n",
       "10     1324     3340     1783    1.879    0.621     1502      584    2.172   \n",
       "11     1745     3341     1532    2.169    0.629     1749      636    2.234   \n",
       "12     1380     3118     1402    2.076    0.639     1985      732    2.297   \n",
       "13     1388     3427     1738    1.872    0.592     1884      603    2.667   \n",
       "14     1552     3449     1683    2.061    0.531     1761      670    2.248   \n",
       "\n",
       "    ST103TS  ST104CV  ...  ST99SA  ST99TA  ST99TS  ST9SV  MMSCORE_sc  \\\n",
       "0     0.795     2934  ...    3387   2.911   0.660   1623          29   \n",
       "1     0.760     2517  ...    3046   2.850   0.714   1296          29   \n",
       "2     0.778     3397  ...    2832   2.735   0.617   1998          28   \n",
       "3     0.776     3106  ...    2692   3.025   0.596   1493          30   \n",
       "4     0.884     3696  ...    3375   2.736   0.697   1997          26   \n",
       "5     1.023     3919  ...    3152   2.742   0.717   2053          29   \n",
       "6     0.683     3268  ...    2966   2.950   0.653   1474          29   \n",
       "7     0.709     2647  ...    3424   2.737   0.779   3932          30   \n",
       "8     0.649     2570  ...    2794   3.063   0.704   2651          29   \n",
       "9     0.687     4228  ...    3488   2.764   0.626   2135          27   \n",
       "10    0.916     3147  ...    2651   2.225   0.675   2664          27   \n",
       "11    0.996     4009  ...    3420   2.727   0.718   3024          27   \n",
       "12    1.025     3281  ...    3273   2.835   0.694   2951          30   \n",
       "13    0.773     2667  ...    2991   2.449   0.704   1693          27   \n",
       "14    0.882     2659  ...    3280   2.590   0.652   1788          29   \n",
       "\n",
       "    MMSCORE_m06  MMSCORE_m12  MMSCORE_m24  MMSCORE_m36     label  \n",
       "0            29           30           29           30        CN  \n",
       "1            29           28           30           29        CN  \n",
       "2            29           30           28           26        CN  \n",
       "3            29           30           29           30        CN  \n",
       "4            28           28           29           28        CN  \n",
       "5            27           28           25           25       MCI  \n",
       "6            30           29           29           30        CN  \n",
       "7            28           30           29           30        CN  \n",
       "8            28           27           28           27        CN  \n",
       "9            28           28           28           26       MCI  \n",
       "10           23           23           19           19  Dementia  \n",
       "11           25           22           20           14  Dementia  \n",
       "12           30           30           30           30        CN  \n",
       "13           26           29           25           28       MCI  \n",
       "14           30           30           30           30        CN  \n",
       "\n",
       "[15 rows x 333 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data_df = pd.read_csv(\"/Users/shrutidudwadkar/Documents/Dissertation/Final_Data+Code/MRI/Processed/mri_mmse.csv\") \n",
    "mri_data_df.drop(columns=['RID'], inplace=True)\n",
    "mri_data_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total  332  features. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mri_features = mri_data_df.columns.values.tolist()\n",
    "print(\"There are total \", len(mri_features)-1, \" features in MRI and MMSE data. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of subjects across 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = sns.countplot(x=\"label\", data=mri_data_df);\n",
    "for p in graph.patches: \n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x() + p.get_width()/2., height + 0.2, height, ha=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST101SV</th>\n",
       "      <th>ST102CV</th>\n",
       "      <th>ST102SA</th>\n",
       "      <th>ST102TA</th>\n",
       "      <th>ST102TS</th>\n",
       "      <th>ST103CV</th>\n",
       "      <th>ST103SA</th>\n",
       "      <th>ST103TA</th>\n",
       "      <th>ST103TS</th>\n",
       "      <th>ST104CV</th>\n",
       "      <th>...</th>\n",
       "      <th>ST99SA</th>\n",
       "      <th>ST99TA</th>\n",
       "      <th>ST99TS</th>\n",
       "      <th>ST9SV</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1578</td>\n",
       "      <td>2862</td>\n",
       "      <td>1312</td>\n",
       "      <td>2.065</td>\n",
       "      <td>0.609</td>\n",
       "      <td>2305</td>\n",
       "      <td>763</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.795</td>\n",
       "      <td>2934</td>\n",
       "      <td>...</td>\n",
       "      <td>3387</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1623</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>3339</td>\n",
       "      <td>1386</td>\n",
       "      <td>2.297</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1621</td>\n",
       "      <td>631</td>\n",
       "      <td>2.166</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>3046</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1296</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>2719</td>\n",
       "      <td>1477</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1813</td>\n",
       "      <td>622</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.778</td>\n",
       "      <td>3397</td>\n",
       "      <td>...</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>744</td>\n",
       "      <td>3456</td>\n",
       "      <td>1748</td>\n",
       "      <td>1.960</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1792</td>\n",
       "      <td>623</td>\n",
       "      <td>2.496</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3106</td>\n",
       "      <td>...</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1493</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908</td>\n",
       "      <td>2741</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.228</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2095</td>\n",
       "      <td>753</td>\n",
       "      <td>2.518</td>\n",
       "      <td>0.884</td>\n",
       "      <td>3696</td>\n",
       "      <td>...</td>\n",
       "      <td>3375</td>\n",
       "      <td>2.736</td>\n",
       "      <td>0.697</td>\n",
       "      <td>1997</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST101SV  ST102CV  ST102SA  ST102TA  ST102TS  ST103CV  ST103SA  ST103TA  \\\n",
       "0     1578     2862     1312    2.065    0.609     2305      763    2.650   \n",
       "1     1102     3339     1386    2.297    0.702     1621      631    2.166   \n",
       "2     1226     2719     1477    1.781    0.538     1813      622    2.409   \n",
       "3      744     3456     1748    1.960    0.620     1792      623    2.496   \n",
       "4      908     2741     1216    2.228    0.612     2095      753    2.518   \n",
       "\n",
       "   ST103TS  ST104CV  ...  ST99SA  ST99TA  ST99TS  ST9SV  MMSCORE_sc  \\\n",
       "0    0.795     2934  ...    3387   2.911   0.660   1623          29   \n",
       "1    0.760     2517  ...    3046   2.850   0.714   1296          29   \n",
       "2    0.778     3397  ...    2832   2.735   0.617   1998          28   \n",
       "3    0.776     3106  ...    2692   3.025   0.596   1493          30   \n",
       "4    0.884     3696  ...    3375   2.736   0.697   1997          26   \n",
       "\n",
       "   MMSCORE_m06  MMSCORE_m12  MMSCORE_m24  MMSCORE_m36  label  \n",
       "0           29           30           29           30      0  \n",
       "1           29           28           30           29      0  \n",
       "2           29           30           28           26      0  \n",
       "3           29           30           29           30      0  \n",
       "4           28           28           29           28      0  \n",
       "\n",
       "[5 rows x 333 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "mri_data_df['label']= encoder.fit_transform(mri_data_df['label'])\n",
    "mri_data_df['label'].unique()\n",
    "mri_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mri, y_mri = np.split(mri_data_df.to_numpy(), [-1], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test data using 85:15 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mri, X_test_mri, y_train_mri, y_test_mri = train_test_split(X_mri, y_mri, test_size=0.15, random_state=44)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_mri = sc.fit_transform(X_train_mri)\n",
    "X_test_mri = sc.transform(X_test_mri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier using l1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        10\n",
      "         1.0       0.40      0.67      0.50         6\n",
      "         2.0       0.83      0.62      0.71        16\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.71      0.73      0.70        32\n",
      "weighted avg       0.77      0.72      0.73        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier_mri = SGDClassifier(penalty='l1', alpha=0.03, max_iter=10e7, loss='log')\n",
    "classifier_mri.fit(X_train_mri, y_train_mri)\n",
    "y_pred = classifier_mri.predict(X_test_mri)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_mri , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.9142857142857143\n",
      "test score:  0.71875\n",
      "number of features used:  105\n"
     ]
    }
   ],
   "source": [
    "train_score = classifier_mri.score(X_train_mri, y_train_mri)\n",
    "test_score = classifier_mri.score(X_test_mri, y_test_mri)\n",
    "coeff_used = np.sum(classifier_mri.coef_ != 0)\n",
    "\n",
    "print(\"training score: \", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "feat_l1 = list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[0]]) + list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[1]]) + list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[2]])\n",
    "feat_l1 = list(dict.fromkeys(feat_l1))\n",
    "print(\"number of features used: \", len(feat_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8120799339549339\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test_mri, classifier_mri.predict_proba(X_test_mri), multi_class='ovr')\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.6123724356957945\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test_mri, y_pred))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier using l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.70      0.70        10\n",
      "         1.0       0.56      0.83      0.67         6\n",
      "         2.0       0.77      0.62      0.69        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.67      0.72      0.69        32\n",
      "weighted avg       0.71      0.69      0.69        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier_mri_l2 = SGDClassifier(penalty='l2', alpha=0.26, max_iter=10e6, loss='log')\n",
    "\n",
    "classifier_mri_l2.fit(X_train_mri, y_train_mri)\n",
    "y_pred = classifier_mri_l2.predict(X_test_mri)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_mri , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.96\n",
      "test score:  0.6875\n",
      "number of features used:  332\n"
     ]
    }
   ],
   "source": [
    "train_score = classifier_mri_l2.score(X_train_mri, y_train_mri)\n",
    "test_score = classifier_mri_l2.score(X_test_mri, y_test_mri)\n",
    "coeff_used = np.sum(classifier_mri_l2.coef_ != 0)\n",
    "\n",
    "print(\"training score: \", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "\n",
    "feat_l2 = list(mri_data_df.columns[:-1][(classifier_mri_l2.coef_!=0)[0]]) + list(mri_data_df.columns[:-1][(classifier_mri_l2.coef_!=0)[1]]) + list(mri_data_df.columns[:-1][(classifier_mri_l2.coef_!=0)[2]])\n",
    "feat_l2 = list(dict.fromkeys(feat_l2))\n",
    "print(\"number of features used: \", len(feat_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.8838834764831844\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test_mri, y_pred))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results\n",
    "### Lasso and Ridge penalty results on MRI + MMSE dataset\n",
    "\n",
    "| Model | Precision  | Recall  | F1-Score  | Accuracy \n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| **SGD with l1 penalty**  | **0.71** | **0.73**  | **0.70**  | **0.72**  |\n",
    "| SGD with l2 penalty  | 0.67 | 0.72 | 0.69 | 0.69 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
